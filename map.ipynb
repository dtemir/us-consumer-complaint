{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hairy-coffee",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <img src=\"images/logo.png\" width=\"250\" height=\"200\">\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "    To download the previously cleaned dataset click <a href=\"https://drive.google.com/file/d/1mYJws7uPjbPqPszUQHpf4PfrHSEjAVIu/view?usp=sharing\" target=\"__blank\">here</a>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moral-ground",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# set max rows displayed in output to 25\n",
    "pd.set_option(\"display.max_rows\", 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supported-papua",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "df = pd.read_pickle('clean_complaints.pkl')\n",
    "print(\"Shape: \", df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-fisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uszipcode import SearchEngine\n",
    "search = SearchEngine(simple_zipcode=False) # set simple_zipcode=False to use rich info database\n",
    "\n",
    "def complaints_per_zipcode(passed_df):\n",
    "    complaints = pd.DataFrame({'ZIP code': [], 'Number of Complaints': [], 'lat': [], 'lng': [], 'polygon': []})\n",
    "    \n",
    "    # iterate aall unique zips\n",
    "    for zip in passed_df['ZIP code'].unique():\n",
    "        zip_code = str(zip)\n",
    "        number_of_complaints = passed_df[passed_df['ZIP code'] == zip].shape[0]\n",
    "        \n",
    "        # search for zip code's latitude, longtute, and polygons\n",
    "        zipcode = search.by_zipcode(zip_code)\n",
    "        zipcode_dict = zipcode.to_dict()\n",
    "        needed_info = {key: zipcode_dict[key] for key in ['lat', 'lng', 'polygon']}\n",
    "        \n",
    "        lat = needed_info['lat']\n",
    "        lng = needed_info['lng']\n",
    "        polygon = needed_info['polygon']\n",
    "        \n",
    "        new_row = {'ZIP code': zip_code, 'Number of Complaints': number_of_complaints,\n",
    "                  'lat': lat, 'lng': lng, 'polygon': polygon}\n",
    "        complaints = complaints.append(new_row, ignore_index=True)\n",
    "        \n",
    "    return complaints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "complaints = complaints_per_zipcode(df)\n",
    "\n",
    "complaints.set_index('ZIP code', inplace=True)\n",
    "complaints.sort_values(by=['Number of Complaints'], inplace=True, ascending=False)\n",
    "\n",
    "complaints.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "judicial-indianapolis",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are\", complaints['Number of Complaints'].sum(), \"number of complaints in the new dataset (same as the initial dataset)\")\n",
    "print(\"There are\", complaints.shape[0], \"number of unique ZIP codes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-tokyo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REQUIRES a geoJSON file\n",
    "# NEEDS saved complaints dataframe as json\n",
    "# import folium\n",
    "\n",
    "# complaints_map = folium.Map(location=[39.50, -98.35], zoom_start=4)\n",
    "\n",
    "# complaints_map.choropleth(\n",
    "#     geo_data=complaints_no_index['polygon'].tolist()[0:2],\n",
    "#     name=\"choropleth\",\n",
    "#     data=complaints['Number of Complaints'],\n",
    "#     columns=[\"\"],\n",
    "#     key_on=\"feature.id\",\n",
    "#     fill_color=\"YlGn\",\n",
    "#     fill_opacity=0.7,\n",
    "#     line_opacity=0.2,\n",
    "#     legend_name=\"Unemployment Rate (%)\",\n",
    "# ).add_to(complaints_map)\n",
    "\n",
    "# complaints_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moral-energy",
   "metadata": {},
   "outputs": [],
   "source": [
    "complaints.to_json('complaints.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parallel-artist",
   "metadata": {},
   "outputs": [],
   "source": [
    "complaints_no_index = complaints.reset_index()\n",
    "complaints_no_index = complaints_no_index[['lat', 'lng', 'polygon']]\n",
    "complaints_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriental-eugene",
   "metadata": {},
   "outputs": [],
   "source": [
    "complaints_no_index['polygon'].tolist()[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constant-manor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
